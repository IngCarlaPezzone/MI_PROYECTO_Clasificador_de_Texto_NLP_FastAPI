![Python](https://img.shields.io/badge/-Python-333333?style=flat&logo=python)
![TensorFlow](https://img.shields.io/badge/-TensorFlow-333333?style=flat&logo=tensorflow)
![Pandas](https://img.shields.io/badge/-Pandas-333333?style=flat&logo=pandas)
![Numpy](https://img.shields.io/badge/-Numpy-333333?style=flat&logo=numpy)
![Scikitlearn](https://img.shields.io/badge/-Scikitlearn-333333?style=flat&logo=scikitlearn)
![Matplotlib](https://img.shields.io/badge/-Matplotlib-333333?style=flat&logo=Matplotlib)
![FastAPI](https://img.shields.io/badge/-FastAPI-333333?style=flat&logo=fastapi)
![Streamlit](https://img.shields.io/badge/-Streamlit-333333?style=flat&logo=streamlit)
![ChatGPT](https://img.shields.io/badge/-ChatGPT-333333?style=flat&logo=openai)
![Docker](https://img.shields.io/badge/-Docker-333333?style=flat&logo=docker)
![Render](https://img.shields.io/badge/-Render-333333?style=flat&logo=render)
![Postgres](https://img.shields.io/badge/-Postgres-333333?style=flat&logo=postgresql)

# Clasificador de textos con tensorflow y predicci贸n en FastAPI, Streamlit y Deploy en Render

Este proyecto consiste en la clasificaci贸n de textos con un modelo de redes neuronales utilizando LSTM bidireccionales. Para facilitar la interacci贸n con el modelo, se implement贸 una interfaz usando FastAPI. Luego, en las actualizaciones posteriores, se agreg贸 una interfaz de Streamlit y finalmente el deploy en Render.

Para el entrenamiento se recolectaron 150 URL de wikipedia de tres categor铆as distintas. Para obtener el listado de las URL se utiliz贸 ChatGPT y con python se automatiz贸 la extracci贸n de los textos, la limpieza y generaci贸n del conjunto de datos limpio.

Finalmente, se cre贸 una API donde se puede ingresar un nuevo texto y solicitar la clasificaci贸n del mismo.

## Creaci贸n del Conjunto de Datos y Entrenamiento del modelo

Se adjunta una Colab (se puede abrir directamente con el bot贸n de Colab) donde explica paso a paso para:
- armar el conjunto de datos, 
- realizar la limpieza de los textos,
- hacer el acondicionamiento para usarlo en el modelo,
- crear y entrenar el modelo,
- evaluar el modelo,
- realizar una predicci贸n.

## Clonar este repositorio
Para realizar la interacci贸n con FastAPI y/o con Streamlit se necesita clonar el repositorio. Para ello, elegir una carpeta donde se quiera guardar el proyecto y abrir una terminal en dicha ubicaci贸n.
Hacer `git clone https://github.com/IngCarlaPezzone/MI_PROYECTO_Clasificador_de_Texto_NLP_FastAPI.git` para clonar el proyecto.

## Interacci贸n con la interfaz de FastAPI

En caso de querer interactuar con el modelo desde la interfaz que proporciona FastAPI, se deber谩n seguir los siguientes pasos:

- Preparaci贸n del entorno de trabajo en Visual Studio Code:
    * Crear entorno `Python -m venv env`
    * Ingresar al entorno haciendo `venv\Scripts\activate`
    * Instalar dependencias con `pip install -r requirements.txt`
- Descargar la carpeta modelos que se genera en Colab y que contiene `Pesos_modelo.h5` y `tokenizador.json` y guardarlo en la carpeta de trabajo.
- Ejecutar el archivo api.py desde consola activando uvicorn. Para ello, hacer `uvicorn api:app --reload`
- Hacer Ctrl + clic sobre la direcci贸n `http://XXX.X.X.X:XXXX` (se muestra en la consola).
- Una vez en el navegador, agregar `/docs` para acceder a ReDoc.
- En POST hacer clic en Try it out y luego introducir el texto a clasificar en el campo requerido texto. Finalmente Ejecutar y observar la predicci贸n.

# Actualizaci贸n!! (18/07/23)

## Interacci贸n con la interfaz de Streamlit

Streamlit es una biblioteca de Python que permite crear aplicaciones web interactivas y visualizaciones de datos de manera r谩pida y sencilla.

Para poder usarlo, se deber谩n seguir los siguientes pasos:

- Clonar el repositorio (ver punto anterior)
- Preparaci贸n del entorno de trabajo en Visual Studio Code (ver punto anterior)
- Ejecutar `streamlit run st_app.py` desde consola. Se abrir谩 una nueva pesta帽a en el navegador.
- Una vez en el navegador, ingresar el nuevo texto y presionar en el bot贸n para obtener la predicci贸n.

As铆 se ve la interfaz:

![](https://github.com/IngCarlaPezzone/MI_PROYECTO_Clasificador_de_Texto_NLP_FastAPI/blob/main/images/app_streamlit.png)

# Actualizaci贸n!! (26/08/23)

## Deploy de la app de streamlit en render.com

Se hizo el deploy de la aplicaci贸n realizada en streamlit en `render.com` que es una nube unificada para crear y ejecutar aplicaciones y sitios web y despliegues autom谩ticos desde Git. Para poder deployar este proyecto se siguieron estos pasos:

- Generaci贸n de un Dockerfile cuya imagen es Python 3.10. Esto se hace porque Render usa por defecto Python 3.7, lo que no es compatible con las versiones de las librer铆as trabajadas en este proyecto, por tal motivo, se opct贸 por deployar el proyecto dentro de este contenedor. Por otra parte, tambi茅n fue necesario agregar en la creaci贸n del contenedor la descarga de las stopwords y wordnet de NLTK, dado que en el scrip original del proyecto se hac铆a mediante descarga y esto no es posible durante el deploy. Se puede ver el detalle del documento [Dockerfile](Dockerfile).
- Se gener贸 un servicio **Web Service** nuevo  en `render.com`, conectado al presente repositorio y utilizando Docker como Runtime.
- Finalmente, el servicio queda corriendo en [https://clasificatexto.onrender.com/](https://clasificatexto.onrender.com/).

# Actualizaci贸n!! (18/09/23)

## Integraci贸n con una base de datos Postgres

Se agregaron nuevas funcionalidades a la aplicaci贸n de streamlit para guardar el texto ingresado por el usuario, la predicci贸n del modelo y la calificaci贸n de la predicci贸n. En este 煤ltimo punto se agregaron secciones a la aplicaci贸n para que el usuario califique la predicci贸n como  o . En caso de que el modelo se haya equivocado, y el usuario califique como negativo, se permite al usuario que indique cu谩l era la predicci贸n real del texto ingresado. De esta manera, se guardan todos estos datos para evaluar el modelo y para un futuro reentrenamiento del modelo.

Para hacer esta integraci贸n con la base de datos se realizaron los siguientes pasos:

- Se modific贸 el c贸digo [st_app.py](st_app.py) para agregar las nuevas funcionalidades.
- Se creo el archivo [pgadmin_connect_render.py](pgadmin_connect_render.py) donde contiene la conexi贸n a la base de datos Postgres que proporciona Render y las funciones que permiten guarda los datos a la base de datos.
- Se agreg贸 un nuevo servicio **PostgreSQL** en `render.com`.
- Se agreg贸 como variable de ambiente la **Internal Database URL** para conectar el proyecto con la base de datos de Render.
- Se creo una base de datos en `pgAdmin` conectada a la **External Database URL** para conectar con la base de datos de Render. All铆 se cre贸 una nueva tabla *predicciones* con los *campos id*, *texto*, *resultado*, *probabilidad_formateada* y *calificacion* donde se almacenan los datos generados por la aplicaci贸n.
- Finalmente, el servicio queda corriendo en [https://clasificatexto.onrender.com/](https://clasificatexto.onrender.com/). 

A continuaci贸n, se muestran algunas im谩genes de la aplicaci贸n:

### Opciones para calificar la predicci贸n

![](https://github.com/IngCarlaPezzone/MI_PROYECTO_Clasificador_de_Texto_NLP_FastAPI/blob/main/images/opciones_calificacion.png)

### Resultado de predicci贸n positiva

![](https://github.com/IngCarlaPezzone/MI_PROYECTO_Clasificador_de_Texto_NLP_FastAPI/blob/main/images/predicci%C3%B3n_positiva.png)

### Opciones cuando la predicci贸n fue negativa

Aca se muestran las opciones distintas a la que predijo el modelo. Porque si califica la predicci贸n como  quiere decir que esa categor铆a no era correcta y debe elegir por alguna de las otras dos categor铆as.

![](https://github.com/IngCarlaPezzone/MI_PROYECTO_Clasificador_de_Texto_NLP_FastAPI/blob/main/images/opciones_negativa.png)
